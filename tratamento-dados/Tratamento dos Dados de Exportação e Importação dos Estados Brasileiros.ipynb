{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJWffFURdGgs"
   },
   "source": [
    "# Tratamento dos Dados de Exportação e Importação dos Estados Brasileiros\n",
    "\n",
    "*Execute este arquivo no [![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Bug-Busters-F/alfalog/blob/feat/notebooks/tratamento-dados/Tratamento%20dos%20Dados%20de%20Exporta%C3%A7%C3%A3o%20e%20Importa%C3%A7%C3%A3o%20dos%20Estados%20Brasileiros.ipynb)*.\n",
    "\n",
    "Leitura e limpeza dos dados abertos do Ministério do Desenvolvimento, Indústria, Comércio e Serviços.\n",
    "\n",
    "Este notebook pertence projeto [Alfalog](https://github.com/Bug-Busters-F/alfalog) encontrado neste [link](https://github.com/Bug-Busters-F/alfalog)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_FA31HCdzhp"
   },
   "source": [
    "O script abaixo irá realizar a leitura e limpeza dos dados do COMEX. Para isso, irá gerar dois arquivos CSV, um de exportação e um de importação, que serão salvos no Google Drive no diretório configurado em `DRIVE_TARGET`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 4841,
     "status": "error",
     "timestamp": 1747791274126,
     "user": {
      "displayName": "Wesley Gonçalves",
      "userId": "07462819282728935151"
     },
     "user_tz": 180
    },
    "id": "I7dFMjVxeUvO",
    "outputId": "1267ea08-220c-4123-d8e3-b20dfad8d2db"
   },
   "outputs": [
    {
     "ename": "MessageError",
     "evalue": "Error: credential propagation was unsuccessful",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0157fa43fb4b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mDRIVE_TARGET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"comex_data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdrive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/drive/MyDrive/{DRIVE_TARGET}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdrive_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "\n",
    "DRIVE_TARGET = \"comex_data\"\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "drive_path = Path(f\"/content/drive/MyDrive/{DRIVE_TARGET}\")\n",
    "drive_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "base_url = \"https://balanca.economia.gov.br/balanca/bd/comexstat-bd/ncm/\"\n",
    "tables_url = \"https://balanca.economia.gov.br/balanca/bd/tabelas/\"\n",
    "\n",
    "def download_csv(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return pd.read_csv(StringIO(response.text), sep=';', on_bad_lines='warn')\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(StringIO(response.text), sep=';', on_bad_lines='skip')\n",
    "\n",
    "def process_comercio_exterior(tipo='EXP', anos=None):\n",
    "    tipo = tipo.upper()\n",
    "    linhas_base = 0\n",
    "    if tipo not in ['EXP', 'IMP']:\n",
    "        raise ValueError(\"Tipo deve ser 'EXP' (exportação) ou 'IMP' (importação)\")\n",
    "\n",
    "    if anos is None:\n",
    "        from datetime import datetime\n",
    "        ano_final = datetime.now().year\n",
    "        ano_inicial = ano_final - 11\n",
    "        anos = range(ano_inicial, ano_final)\n",
    "    elif isinstance(anos, int):\n",
    "        anos = [anos]\n",
    "    elif isinstance(anos, (list, tuple)):\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Anos deve ser um inteiro, lista ou tupla\")\n",
    "\n",
    "    print(\"Baixando tabelas de relacionamento...\")\n",
    "    paises = download_csv(tables_url + \"PAIS.csv\")[['CO_PAIS', 'NO_PAIS']]\n",
    "    ufs = download_csv(tables_url + \"UF.csv\")[['SG_UF', 'NO_UF']]\n",
    "    vias = download_csv(tables_url + \"VIA.csv\")[['CO_VIA', 'NO_VIA']]\n",
    "    urf = download_csv(tables_url + \"URF.csv\")[['CO_URF', 'NO_URF']]\n",
    "    ncm = download_csv(tables_url + \"NCM.csv\")[['CO_NCM', 'NO_NCM_POR']]\n",
    "\n",
    "    all_data = []\n",
    "    total_removed = {\n",
    "        'column_filter': 0,\n",
    "        'unit_filter': 0,\n",
    "        'country_filter': 0,\n",
    "        'uf_filter': 0,\n",
    "        'via_filter1': 0,\n",
    "        'via_filter2': 0,\n",
    "        'qt_estat_filter': 0,\n",
    "        'vl_fob_filter': 0,\n",
    "        'ncm_freq_filter': 0,\n",
    "        'pais_freq_filter': 0,\n",
    "        'frete_filter': 0,\n",
    "        'seguro_filter': 0,\n",
    "        'outlier_filter': 0,\n",
    "        'merge_loss': 0\n",
    "    }\n",
    "\n",
    "    for year in anos:\n",
    "        print(f\"\\nProcessando ano {year}...\")\n",
    "        try:\n",
    "            url = f\"{base_url}{tipo}_{year}.csv\"\n",
    "            df = download_csv(url)\n",
    "            initial_rows = len(df)\n",
    "            linhas_base += initial_rows\n",
    "            print(f\"Linhas iniciais: {initial_rows}\")\n",
    "            before = len(df)\n",
    "            expected_columns = [\n",
    "                'CO_ANO', 'CO_MES', 'CO_NCM', 'CO_UNID', 'CO_PAIS', 'SG_UF_NCM',\n",
    "                'CO_VIA', 'CO_URF', 'QT_ESTAT', 'KG_LIQUIDO', 'VL_FOB'\n",
    "            ]\n",
    "\n",
    "            before = len(df)\n",
    "            df = df[df[\"CO_UNID\"] != 18].copy()\n",
    "            total_removed['unit_filter'] += (before - len(df))\n",
    "\n",
    "            before = len(df)\n",
    "            df = df[~df[\"CO_PAIS\"].isin([0, 990, 994, 995, 997, 998, 999])].copy()\n",
    "            total_removed['country_filter'] += (before - len(df))\n",
    "\n",
    "            before = len(df)\n",
    "            df = df[~df[\"SG_UF_NCM\"].isin([\"ND\", \"ZN\", \"ED\", \"RE\", \"MN\", \"CB\", \"EX\"])].copy()\n",
    "            total_removed['uf_filter'] += (before - len(df))\n",
    "\n",
    "            before = len(df)\n",
    "            df = df[~df[\"CO_VIA\"].isin([0, 8, 10, 11, 12, 13, 99])].copy()\n",
    "            total_removed['via_filter1'] += (before - len(df))\n",
    "\n",
    "            before = len(df)\n",
    "            vias_terrestres = [7, 6]\n",
    "            paises_fronteira = [63, 97, 169, 337, 325, 586, 589, 770, 845, 850]\n",
    "            df = df[~((df[\"CO_VIA\"].isin(vias_terrestres)) & (~df[\"CO_PAIS\"].isin(paises_fronteira)))].copy()\n",
    "            total_removed['via_filter2'] += (before - len(df))\n",
    "\n",
    "            before = len(df)\n",
    "            df = df[df[\"QT_ESTAT\"] != 0].copy()\n",
    "            total_removed['qt_estat_filter'] += (before - len(df))\n",
    "\n",
    "            before = len(df)\n",
    "            df = df[df[\"VL_FOB\"] != 0].copy()\n",
    "            total_removed['vl_fob_filter'] += (before - len(df))\n",
    "\n",
    "            before = len(df)\n",
    "            ncms_frequentes = df[\"CO_NCM\"].value_counts()[df[\"CO_NCM\"].value_counts() > 5].index\n",
    "            df = df[df[\"CO_NCM\"].isin(ncms_frequentes)].copy()\n",
    "            total_removed['ncm_freq_filter'] += (before - len(df))\n",
    "\n",
    "            before = len(df)\n",
    "            paises_frequentes = df[\"CO_PAIS\"].value_counts()[df[\"CO_PAIS\"].value_counts() > 10].index\n",
    "            df = df[df[\"CO_PAIS\"].isin(paises_frequentes)].copy()\n",
    "            total_removed['pais_freq_filter'] += (before - len(df))\n",
    "\n",
    "            before = len(df)\n",
    "            Q1 = df[\"KG_LIQUIDO\"].quantile(0.25)\n",
    "            Q3 = df[\"KG_LIQUIDO\"].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            df = df[(df[\"KG_LIQUIDO\"] >= Q1 - 1.5*IQR) & (df[\"KG_LIQUIDO\"] <= Q3 + 1.5*IQR)].copy()\n",
    "            total_removed['outlier_filter'] += (before - len(df))\n",
    "\n",
    "            df['ANO'] = year\n",
    "            all_data.append(df)\n",
    "            print(f\"Linhas restantes após todos os filtros: {len(df)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no ano {year}: {str(e)}\")\n",
    "\n",
    "    if not all_data:\n",
    "        raise ValueError(\"Nenhum dado válido foi processado\")\n",
    "\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    before_merge = len(final_df)\n",
    "    final_df = final_df.merge(paises, on='CO_PAIS', how='left')\n",
    "    final_df = final_df.merge(ufs, left_on='SG_UF_NCM', right_on='SG_UF', how='left')\n",
    "    final_df = final_df.merge(vias, on='CO_VIA', how='left')\n",
    "    final_df = final_df.merge(urf, on='CO_URF', how='left')\n",
    "    final_df = final_df.merge(ncm, on='CO_NCM', how='left')\n",
    "\n",
    "    cols_order = [\n",
    "        'ANO', 'CO_MES', 'NO_NCM_POR', 'NO_PAIS', 'SG_UF_NCM', 'NO_UF',\n",
    "        'NO_VIA', 'NO_URF', 'KG_LIQUIDO', 'CO_UNID', 'VL_FOB'\n",
    "    ]\n",
    "    final_df[\"NO_VIA\"] = final_df[\"NO_VIA\"].replace({\n",
    "        \"MARÍTIMA\": \"AQUÁTICA\", \"FLUVIAL\": \"AQUÁTICA\", \"LACUSTRE\": \"AQUÁTICA\"\n",
    "    })\n",
    "    final_df = final_df[cols_order].rename(columns={'SG_UF_NCM': 'SG_UF'})\n",
    "\n",
    "    output_file = drive_path / f'dados_comex_{tipo}_{min(anos)}_{max(anos)}.csv'\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Resumo estatístico consolidado\n",
    "    print(\"\\nRESUMO CONSOLIDADO DE FILTRAGEM (TODOS OS ANOS):\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total de linhas iniciais: {linhas_base}\")\n",
    "    print(f\"Total de linhas finais: {len(final_df)}\")\n",
    "    print(f\"Total geral de linhas removidas: {linhas_base - len(final_df)}\")\n",
    "    print(\"\\nDetalhe por tipo de filtro:\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Filtro de unidades (CO_UNID != 18): {total_removed['unit_filter']}\")\n",
    "    print(f\"Filtro de países inválidos: {total_removed['country_filter']}\")\n",
    "    print(f\"Filtro de UFs inválidas: {total_removed['uf_filter']}\")\n",
    "    print(f\"Filtro de vias inválidas: {total_removed['via_filter1']}\")\n",
    "    print(f\"Filtro de vias terrestres inconsistentes: {total_removed['via_filter2']}\")\n",
    "    print(f\"Filtro de quantidade estatística zero: {total_removed['qt_estat_filter']}\")\n",
    "    print(f\"Filtro de valor FOB zero: {total_removed['vl_fob_filter']}\")\n",
    "    print(f\"Filtro de NCMs pouco frequentes: {total_removed['ncm_freq_filter']}\")\n",
    "    print(f\"Filtro de países pouco frequentes: {total_removed['pais_freq_filter']}\")\n",
    "    if total_removed['frete_filter'] > 0:\n",
    "        print(f\"Filtro de frete inconsistente: {total_removed['frete_filter']}\")\n",
    "    if total_removed['seguro_filter'] > 0:\n",
    "        print(f\"Filtro de seguro inconsistente: {total_removed['seguro_filter']}\")\n",
    "    print(f\"Filtro de outliers: {total_removed['outlier_filter']}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(f\"\\nProcesso concluído! Arquivo salvo em: {output_file}\")\n",
    "    return final_df\n",
    "df = process_comercio_exterior()\n",
    "df2 = process_comercio_exterior('IMP')\n",
    "df.head(10)\n",
    "# df2.head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1WRSAEERIYsReXWyuLLLTs28WkV41tFyW",
     "timestamp": 1747790535406
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
